import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image, ImageEnhance, ImageOps
import numpy as np
import matplotlib.pyplot as plt
from model_utils import UNet
from ultralytics import YOLO
import io
import os
import datetime
from reportlab.lib.pagesizes import letter
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as ReportLabImage, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_CENTER, TA_LEFT

# Device Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- PDF Generation ---
def create_pdf(patient_name, patient_id, doctor_name, diagnosis, confidence, original_img, mask_img=None):
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
    story = []
    
    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name='CenterTitle', parent=styles['Heading1'], alignment=TA_CENTER, spaceAfter=20))
    styles.add(ParagraphStyle(name='SectionHeader', parent=styles['Heading2'], spaceAfter=10))
    styles.add(ParagraphStyle(name='NormalLeft', parent=styles['Normal'], alignment=TA_LEFT, spaceAfter=5))

    # Header
    story.append(Paragraph("NeuroScan Diagnostic Report", styles['CenterTitle']))
    story.append(Paragraph(f"Generated on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal']))
    story.append(Spacer(1, 12))
    
    # Patient Information Table
    data = [
        ["Patient Information", ""],
        ["Patient Name:", patient_name],
        ["Patient ID:", patient_id],
        ["Attending Physician:", doctor_name]
    ]
    
    table = Table(data, colWidths=[150, 300])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (1, 0), colors.Color(0.17, 0.24, 0.31)), # Dark Blue Header
        ('TEXTCOLOR', (0, 0), (1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.whitesmoke),
        ('GRID', (0, 0), (-1, -1), 1, colors.white)
    ]))
    story.append(table)
    story.append(Spacer(1, 20))
    
    # Diagnosis Section
    story.append(Paragraph("Diagnostic Analysis", styles['SectionHeader']))
    
    diag_data = [
        ["Primary Diagnosis", diagnosis],
        ["Confidence Score", f"{confidence:.2f}%"]
    ]
    
    diag_table = Table(diag_data, colWidths=[150, 300])
    diag_table.setStyle(TableStyle([
        ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
        ('TEXTCOLOR', (1, 0), (1, 0), colors.red if diagnosis != 'NOTUMOR' else colors.green),
    ]))
    story.append(diag_table)
    story.append(Spacer(1, 20))
    
    # Images
    story.append(Paragraph("Medical Imaging", styles['SectionHeader']))
    
    # Process Images
    img_width = 220
    img_height = 220
    
    # Save PIL images to temporary buffers for ReportLab
    img_buffer = io.BytesIO()
    original_img.save(img_buffer, format='PNG')
    img_buffer.seek(0)
    
    rl_orig_img = ReportLabImage(img_buffer, width=img_width, height=img_height)
    
    images_row = [rl_orig_img]
    
    if mask_img is not None:
         if isinstance(mask_img, np.ndarray):
             if mask_img.max() <= 1.0:
                 mask_img = (mask_img * 255).astype(np.uint8)
             mask_pil = Image.fromarray(mask_img)
         else:
             mask_pil = mask_img
             
         if mask_pil.mode != 'L':
             mask_pil = mask_pil.convert('L')
             
         mask_buffer = io.BytesIO()
         mask_pil.save(mask_buffer, format='PNG')
         mask_buffer.seek(0)
         
         rl_mask_img = ReportLabImage(mask_buffer, width=img_width, height=img_height)
         images_row.append(rl_mask_img)
    
    # Create a table for side-by-side images
    img_table = Table([images_row], colWidths=[250, 250])
    img_table.setStyle(TableStyle([
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('VALIGN', (0, 0), (-1, -1), 'TOP'),
    ]))
    story.append(img_table)
    
    captions = ["Original Scan"]
    if len(images_row) > 1:
        captions.append("Tumor Segmentation")
        
    caption_table = Table([captions], colWidths=[250, 250])
    caption_table.setStyle(TableStyle([
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Oblique'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
    ]))
    story.append(caption_table)
    story.append(Spacer(1, 30))
    
    # Disclaimer
    story.append(Paragraph("Disclaimer: This report is generated by an AI assistant (NeuroScan) for educational/reference purposes only. It is not a substitute for professional medical advice, diagnosis, or treatment.", styles['Normal']))

    doc.build(story)
    return buffer.getvalue()

# --- Model Loading ---
@st.cache_resource
def load_classification_model():
    try:
        model = models.mobilenet_v2(weights=None)
        # Recreate head
        num_ftrs = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(num_ftrs, 4) # 4 classes
        
        # Load weights
        model_path = 'classification_model.pth'
        # Check if exists, else return None (handle gracefully if running app before training done)
        if hasattr(st, "session_state") and "mock_mode" not in st.session_state:
             # In a real scenario, we might wait or show a warning
             pass
             
        state_dict = torch.load(model_path, map_location=device)
        model.load_state_dict(state_dict)
        model = model.to(device)
        model.eval()
        return model
    except FileNotFoundError:
        st.warning("Classification model not found. Please train the model first.")
        return None
    except Exception as e:
        st.error(f"Error loading classification model: {e}")
        return None

@st.cache_resource
def load_unet_model():
    # Load specialized U-Net for Brain Tumor Segmentation
    try:
        model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',
                               in_channels=3, out_channels=1, init_features=32, pretrained=True)
        model = model.to(device)
        model.eval()
        return model
    except Exception as e:
        st.error(f"Error loading U-Net model: {e}")
        return None

@st.cache_resource
def load_yolo_model():
    # Load YOLOv11 model from Hugging Face
    try:
        model_url = "https://huggingface.co/sajjadhadi/YOLOv11-Tumor-Detection/resolve/main/best.pt"
        model_name = "yolo_tumor_best.pt"
        
        if not os.path.exists(model_name):
            st.info("Downloading YOLOv11 Tumor Detection Model (~20MB)...")
            torch.hub.download_url_to_file(model_url, model_name)
            
        model = YOLO(model_name)
        return model
    except Exception as e:
        st.error(f"Error loading YOLO model: {e}")
        return None

# --- Preprocessing ---
def resize_with_pad(image, target_size=(256, 256)):
    """Resize image maintaining aspect ratio and padding with zero."""
    original_size = image.size
    ratio = min(target_size[0] / original_size[0], target_size[1] / original_size[1])
    new_size = (int(original_size[0] * ratio), int(original_size[1] * ratio))
    
    img_resized = image.resize(new_size, Image.Resampling.LANCZOS)
    
    new_img = Image.new("RGB", target_size)
    new_img.paste(img_resized, ((target_size[0] - new_size[0]) // 2,
                                (target_size[1] - new_size[1]) // 2))
    return new_img

def preprocess_image(image):
    # Classification transform
    # MobileNet expects 224x224, simpler resize is usually fine but padding is safer
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return transform(image).unsqueeze(0).to(device)

def preprocess_unet(image):
    # U-Net specific preprocessing
    # 1. Resize with Pad to 256x256 to avoid distortion
    img_padded = resize_with_pad(image, (256, 256))
    
    # 2. To Tensor
    transform_to_tensor = transforms.Compose([
        transforms.ToTensor()
    ])
    img_tensor = transform_to_tensor(img_padded)
    
    # 3. Z-score normalization
    mean = torch.mean(img_tensor)
    std = torch.std(img_tensor)
    if std > 0:
        img_tensor = (img_tensor - mean) / std
    else:
        img_tensor = img_tensor - mean
        
    return img_tensor.unsqueeze(0).to(device)

# --- App Logic ---
def main():
    st.sidebar.title("NeuroScan")
    st.sidebar.markdown("Medical Diagnostic Assistant")
    
    # Model Selection
    st.sidebar.markdown("---")
    st.sidebar.subheader("Configuration")
    seg_model_choice = st.sidebar.selectbox("Segmentation Model", 
                                          ["YOLOv11 (Robust)", "U-Net (Experimental)"],
                                          index=0)
    
    model_conf = st.sidebar.slider("Confidence Threshold", 0.1, 0.9, 0.25, 0.05) # Lower default conf for better recall


    st.sidebar.markdown("---")
    page = st.sidebar.radio("Navigation", ["Home", "Analysis", "About"])

    if page == "Home":
        st.title("NeuroScan Diagnostic System")
        st.markdown("### Advanced AI-Powered Brain Tumor Detection")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            **NeuroScan** maximizes diagnostic accuracy using state-of-the-art deep learning models.
            
            **Key Features:**
            - **Tumor Classification**: Identifies tumor type (Glioma, Meningioma, Pituitary) or confirms absence.
            - **Precise Segmentation**: Localizes tumor boundaries using specialized models.
            - **Report Generation**: Instantly create downloadable PDF reports for patient records.
            """)
        with col2:
             # Basic medical icon or similar if we had one, otherwise just text
             st.info(f"Active Model: {seg_model_choice}")

    elif page == "Analysis":
        st.title("Diagnostic Analysis")
        
        st.subheader("1. Patient Information")
        with st.container():
            col1, col2 = st.columns(2)
            with col1:
                patient_name = st.text_input("Patient Name", placeholder="Enter full name")
                patient_id = st.text_input("Patient ID", placeholder="Record ID / MRN")
            with col2:
                doctor_name = st.text_input("Attending Physician", placeholder="Dr. Name")
        
        st.markdown("---")
        st.subheader("2. MRI Scan Upload")
        uploaded_file = st.file_uploader("Upload Brain MRI Scan (JPG, PNG, JPEG)", type=["jpg", "png", "jpeg"])
        
        # Initialize session state for results if not present
        if 'analysis_results' not in st.session_state:
            st.session_state.analysis_results = None
            
        # Reset results if new file uploaded
        if uploaded_file is not None:
             # Check if file changed, if so clear results. 
             pass
        else:
            st.session_state.analysis_results = None

        if uploaded_file is not None:
            image_raw = Image.open(uploaded_file).convert("RGB")
            
            # --- Image Enhancements ---
            with st.expander("Image Enhancements", expanded=True):
                col1, col2, col3 = st.columns(3)
                with col1:
                    brightness = st.slider("Brightness", 0.5, 2.0, 1.0, 0.1)
                with col2:
                    sharpness = st.slider("Sharpness", 0.5, 2.0, 1.0, 0.1)
                with col3:
                    invert = st.checkbox("Invert Colors", value=False)
                    
            # Apply enhancements
            enhancer = ImageEnhance.Brightness(image_raw)
            image = enhancer.enhance(brightness)
            
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(sharpness)
            
            if invert:
                image = ImageOps.invert(image)
            
            st.image(image, caption="Processed Scan", width=300)
            
            if st.button("Initiate Analysis", type="primary"):
                if not patient_name:
                    st.warning("Please enter Patient Name to proceed.")
                else:
                    with st.spinner("Analyzing scan data..."):
                        # Classification
                        cls_model = load_classification_model()
                        pred_class = "Unknown"
                        confidence = 0.0
                        
                        if cls_model:
                            input_tensor = preprocess_image(image)
                            with torch.no_grad():
                                outputs = cls_model(input_tensor)
                                _, preds = torch.max(outputs, 1)
                                probs = torch.nn.functional.softmax(outputs, dim=1)
                                
                            class_names = ['glioma', 'meningioma', 'notumor', 'pituitary'] 
                            pred_class = class_names[preds[0]]
                            confidence = probs[0][preds[0]].item() * 100
                            
                        # Segmentation
                        mask_np = np.zeros((256, 256))
                        
                        # Pad image for better segmentation reference
                        img_display = resize_with_pad(image, (256, 256))
                        
                        if "U-Net" in seg_model_choice:
                            seg_model = load_unet_model()
                            if seg_model:
                                seg_input = preprocess_unet(image)
                                with torch.no_grad():
                                    selection = seg_model(seg_input)
                                    prob_map = torch.sigmoid(selection)
                                    output_mask = (prob_map > model_conf).float().squeeze()
                                    mask_np = output_mask.cpu().numpy()
                        else:
                            # YOLO
                            seg_model = load_yolo_model()
                            if seg_model:
                                # YOLO handles its own resizing, but we want mask to match 256x256 display
                                # Use retina_masks=True for pixel-precise segmentation (high res masks)
                                results = seg_model.predict(image, conf=model_conf, retina_masks=True)
                                result = results[0]
                                if result.masks is not None:
                                    masks_tensor = result.masks.data
                                    if masks_tensor is not None and masks_tensor.shape[0] > 0:
                                        # Ensure float for interpolation
                                        output_mask = torch.any(masks_tensor, dim=0).float()
                                        output_mask = torch.nn.functional.interpolate(output_mask.unsqueeze(0).unsqueeze(0), size=(256, 256), mode='nearest').squeeze()
                                        mask_np = output_mask.cpu().numpy()
                        
                        # SANITY CHECK: Discard masks that cover >95% of the image (likely hallucination)
                        if np.mean(mask_np) > 0.95:
                            mask_np = np.zeros((256, 256))
                            st.toast("Warning: Discarded invalid full-image mask detection.")
                            
                        # Store results in session state
                        st.session_state.analysis_results = {
                            'pred_class': pred_class,
                            'confidence': confidence,
                            'mask_np': mask_np,
                            'original_image': img_display, # Use the padded image for display
                        }
             
             # Display Results if available
            if st.session_state.analysis_results:
                results = st.session_state.analysis_results
                pred_class = results['pred_class']
                confidence = results['confidence']
                mask_np = results['mask_np']
                img_disp = results['original_image'] # Already 256x256 padded
                                
                # --- Visualization Logic ---
                st.markdown("### Analysis Results")
                
                if pred_class == 'notumor':
                    st.success(f"**Diagnosis:** {pred_class.upper()} (Confidence: {confidence:.2f}%)")
                else:
                    st.error(f"**Diagnosis:** {pred_class.upper()} (Confidence: {confidence:.2f}%)")
                    
                # Visualization
                cols = st.columns(3)
                
                with cols[0]:
                    st.image(img_disp, caption="Original Scan (Padded)", use_container_width=True)
                with cols[1]:
                    st.image(mask_np, caption="Segmentation Mask", clamp=True, channels='GRAY', use_container_width=True)
                with cols[2]:
                    # Overlay
                    # Convert PIL to np
                    img_np = np.array(img_disp)
                    fig, ax = plt.subplots(figsize=(4, 4))
                    ax.imshow(img_np)
                    if np.max(mask_np) > 0:
                        masked_overlay = np.ma.masked_where(mask_np == 0, mask_np)
                        ax.imshow(masked_overlay, alpha=0.5, cmap='autumn', vmin=0, vmax=1)
                    ax.axis('off')
                    st.pyplot(fig, use_container_width=True)
                
                if np.max(mask_np) == 0:
                     st.info(f"No tumor regions detected by {seg_model_choice}. Try lowering confidence threshold.")
                else:
                     st.info(f"Tumor detected by {seg_model_choice}. Mask Coverage: {np.mean(mask_np)*100:.2f}%")
                    
                # Report Generation
                st.markdown("---")
                st.subheader("3. Report Generation")
                
                if patient_name:
                    # Explicit Generate Button to fix state race conditions
                    if st.button("Generate Report"):
                         with st.spinner("Generating PDF..."):
                            # Sanitize filename
                            safe_name = "".join([c for c in patient_name if c.isalnum() or c in (' ', '-', '_')]).strip().replace(' ', '_')
                            if not safe_name:
                                safe_name = "Patient"
                            
                            current_file_name = f"NeuroScan_Report_{safe_name}.pdf"
                            
                            # Generate PDF
                            pdf_data = create_pdf(
                                patient_name=patient_name,
                                patient_id=patient_id,
                                doctor_name=doctor_name,
                                diagnosis=pred_class.upper(),
                                confidence=confidence,
                                original_img=img_resized,
                                mask_img=mask_np
                            )
                            
                            # Update Session State
                            st.session_state.last_pdf_data = pdf_data
                            st.session_state.last_pdf_name = current_file_name
                            st.success("Report Generated! Click download below.")

                    # Show Download Button only if data exists
                    if 'last_pdf_data' in st.session_state and st.session_state.last_pdf_data:
                         st.download_button(
                            label="Download Report (PDF)",
                            data=st.session_state.last_pdf_data,
                            file_name=st.session_state.last_pdf_name,
                            mime="application/octet-stream",
                            key="download_report_btn_final"
                        )
                else:
                    st.warning("Enter patient name to generate report.")

    elif page == "About":
        st.title("About NeuroScan")
        st.markdown("""
        **NeuroScan AI** is a decision support system designed to assist radiologists and neurologists.
        
        **Technology Stack:**
        - **PyTorch**: Deep learning framework
        - **Streamlit**: Interactive web interface
        - **MobileNetV2**: Efficient classification backbone
        - **YOLOv11**: Real-time object detection and segmentation
        
        **Disclaimer:**
        This tool is for educational and research purposes. It is not intended to replace professional medical diagnosis.
        """)

if __name__ == '__main__':
    main()
